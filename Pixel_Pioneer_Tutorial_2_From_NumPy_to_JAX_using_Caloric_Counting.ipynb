{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlDTgFMeboAphmTf9tffGt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaliniAnandaPhD/PIXEL-PIONEERS-TUTORIALS/blob/main/Pixel_Pioneer_Tutorial_2_From_NumPy_to_JAX_using_Caloric_Counting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#High-Performance Computing with JAX for Smart Calorie Counting\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This comprehensive guide delves into the world of JAX, a powerful Python library for accelerated numerical computing and machine learning. By using the example of smart calorie counting, we'll demonstrate why even simple tasks can greatly benefit from JAX's advanced capabilities, such as automatic differentiation, JIT compilation, vectorization, and parallelization.\n",
        "\n",
        "## What is JAX?\n",
        "\n",
        "JAX is a Python library designed to supercharge numerical computations and machine learning research. It extends NumPy and integrates acceleration libraries like XLA, offering support for GPUs and TPUs.\n",
        "\n",
        "### Key Capabilities\n",
        "\n",
        "- **Automatic Differentiation**: Simplifies model optimization.\n",
        "- **Just-in-Time (JIT) Compilation**: Speeds up code execution.\n",
        "- **Vectorization**: Efficient processing across data samples.\n",
        "- **Parallelization**: Utilizes multiple devices (GPUs/TPUs)."
      ],
      "metadata": {
        "id": "kfaNSRL_oK2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the Python Environment\n",
        "\n",
        "### Essential Library Imports\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "fsRdMyGsoOH8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Installing JAX\n",
        "\n",
        "##!pip install jax jaxlib  # Standard installation\n",
        "\n",
        "# For TPU support:\n",
        "##!pip install jax[tpu] --upgrade\n",
        "##import jax.tools.colab_tpu\n",
        "##jax.tools.colab_tpu.setup_tpu()"
      ],
      "metadata": {
        "id": "m6UdhJSAoV1i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Basic JAX Operations Compared with NumPy\n",
        "\n",
        "### Comparing Arrays\n",
        "\n",
        "arr = np.arange(5)\n",
        "print(\"NumPy array:\", arr)\n",
        "\n",
        "arr_jax = jnp.arange(5)\n",
        "print(\"JAX array:\", arr_jax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYJCQz-MoeAG",
        "outputId": "d4093e8f-29d3-4867-889e-03b7396d94de"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy array: [0 1 2 3 4]\n",
            "JAX array: [0 1 2 3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Array Transformations\n",
        "squared_arr = arr ** 2\n",
        "squared_arr_jax = arr_jax ** 2\n",
        "\n",
        "print(\"Squared NumPy array:\", squared_arr)\n",
        "print(\"Squared JAX array:\", squared_arr_jax)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzFAeJ4Noh9K",
        "outputId": "6897a46a-4bc8-403f-bf87-e74caa64a1af"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Squared NumPy array: [ 0  1  4  9 16]\n",
            "Squared JAX array: [ 0  1  4  9 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario: Caloric Adjustment Model\n",
        "Suppose you're building a model to adjust the estimated calorie count of a food item based on some error metric. You have an initial calorie estimate and want to minimize the error between this estimate and the actual calorie count through gradient descent.\n",
        "\n",
        "Using JAX for Automatic Differentiation\n",
        "JAX excels in scenarios like this due to its automatic differentiation capability. You can compute gradients effortlessly, which are essential for optimization algorithms like gradient descent."
      ],
      "metadata": {
        "id": "9JYGuGjbtbfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Automatic Differentiation with `grad`\n",
        "\n",
        "### Simplifying Gradient Computation\n",
        "from jax import grad\n",
        "import jax.numpy as jnp\n",
        "\n",
        "# Function to compute the squared error\n",
        "def squared_error(estimated_calories, actual_calories):\n",
        "    return (estimated_calories - actual_calories) ** 2\n",
        "\n",
        "# Automatic differentiation to find the gradient\n",
        "grad_error = grad(squared_error)\n",
        "\n",
        "# Example data\n",
        "actual_calories = 250.0\n",
        "estimated_calories = 230.0\n",
        "\n",
        "# Compute the gradient\n",
        "gradient = grad_error(estimated_calories, actual_calories)\n",
        "print(\"JAX - Gradient of Error:\", gradient)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M4oUlEbosOa",
        "outputId": "74798f1a-f0ba-4fb1-a9c8-68a6c4b1a51e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JAX - Gradient of Error: -40.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simplification: JAX's grad function automatically calculates the gradient, simplifying the code and reducing the potential for manual errors."
      ],
      "metadata": {
        "id": "c2euI6IWttDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to compute the squared error\n",
        "def squared_error(estimated_calories, actual_calories):\n",
        "    return (estimated_calories - actual_calories) ** 2\n",
        "\n",
        "# Manually compute the gradient\n",
        "def grad_error(estimated_calories, actual_calories):\n",
        "    return 2 * (estimated_calories - actual_calories)\n",
        "\n",
        "# Example data\n",
        "actual_calories = 250.0\n",
        "estimated_calories = 230.0\n",
        "\n",
        "# Compute the gradient\n",
        "gradient = grad_error(estimated_calories, actual_calories)\n",
        "print(\"NumPy - Gradient of Error:\", gradient)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy6HZDT3sloX",
        "outputId": "495cf124-8de8-48c9-e12b-4e73c51e8c5b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy - Gradient of Error: -40.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just in time compilation"
      ],
      "metadata": {
        "id": "fkQ5icnCtppx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jax import jit\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def calculate_calories(batch):\n",
        "    return jnp.sum(batch * 1.2)\n",
        "\n",
        "# Just-In-Time compilation for single-device execution\n",
        "jit_calculate_calories = jit(calculate_calories)\n",
        "\n",
        "data = jnp.array([100, 150, 200, 120, 180, 220])\n",
        "total_calories = jit_calculate_calories(data)\n",
        "print(\"JAX - Total Calories:\", total_calories)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QIC4Q2Wo06O",
        "outputId": "a3c7c584-99bd-439f-8db9-04db435afa27"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JAX - Total Calories: 1164.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "vmap (Vectorized Map): This function is used for vectorizing operations. It allows a function that operates on a single data point to be seamlessly applied to each element of an array. Essentially, vmap transforms a function to operate on arrays elementwise"
      ],
      "metadata": {
        "id": "P396C9tku1as"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jax import vmap\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def calculate_calories(item):\n",
        "    # Simulate calorie calculation for a single item\n",
        "    return item * 1.2\n",
        "\n",
        "# Vectorize the function\n",
        "v_calculate_calories = vmap(calculate_calories)\n",
        "\n",
        "# Example data\n",
        "data = jnp.array([100, 150, 200, 120, 180, 220])  # All items in one array\n",
        "\n",
        "# Apply the vectorized function\n",
        "calories = v_calculate_calories(data)\n",
        "\n",
        "# Aggregate results\n",
        "total_calories = jnp.sum(calories)\n",
        "print(\"JAX (vmap) - Total Calories:\", total_calories)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8F4cjjHvXg-",
        "outputId": "75c6816d-22d1-4b9b-a403-22250aa19d57"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JAX (vmap) - Total Calories: 1164.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, vmap is used to apply calculate_calories across each element of data. The function calculate_calories is written for a single item, and vmap automatically vectorizes it over the batch."
      ],
      "metadata": {
        "id": "Ln6Y4ka7vdOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NumPy Example for Sequential Calculation\n",
        "NumPy does not have built-in parallelization like JAX's pmap. Instead, calculations are done sequentially."
      ],
      "metadata": {
        "id": "hdHKrkGTuoHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate calories for a batch of food items\n",
        "def calculate_calories(batch):\n",
        "    # Simulate a complex calorie calculation\n",
        "    return np.sum(batch * 1.2)\n",
        "\n",
        "# Example data\n",
        "data = np.array([100, 150, 200, 120, 180, 220])  # All items in one array\n",
        "\n",
        "# Sequential execution\n",
        "total_calories = calculate_calories(data)\n",
        "print(\"NumPy - Total Calories:\", total_calories)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIDyVaHsunH3",
        "outputId": "97f376f8-f07d-4807-ee15-f12c4b843829"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy - Total Calories: 1164.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REAL LIFE SCENARIO"
      ],
      "metadata": {
        "id": "CRg-MbNXvmlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprehensive Python and JAX Tutorial for Advanced Calorie Counting\n",
        "\n",
        "## Expanded Setup\n",
        "\n",
        "### Enhanced Library Import\n",
        "\n",
        "import jax  # Main JAX library for high-performance numerical computing\n",
        "import jax.numpy as jnp  # JAX version of NumPy with GPU/TPU support\n",
        "import numpy as np  # Standard NumPy for comparison and data manipulation\n",
        "import pandas as pd  # Data analysis and manipulation tool"
      ],
      "metadata": {
        "id": "jXxsk5PXpKhd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Creating More Complex Sample Data\n",
        "# Nutritional information (protein, carbs, fat) for three different food items\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Setting a seed for reproducibility\n",
        "random.seed(0)\n",
        "\n",
        "# Number of days\n",
        "num_days = 10\n",
        "\n",
        "# Nutrients: Protein, Carbs, Fat\n",
        "num_nutrients = 3\n",
        "\n",
        "# Generating random nutritional information for each day\n",
        "nutrients = np.array([[random.randint(10, 50) for _ in range(num_nutrients)] for _ in range(num_days)])\n",
        "\n",
        "# Densities in calories per gram for Protein, Carbs, and Fat\n",
        "densities = np.array([4, 4, 9])  # 4 calories/gram for Protein and Carbs, 9 for Fat\n",
        "\n",
        "# Displaying the nutritional information\n",
        "print(\"Nutritional Information (Protein, Carbs, Fat) over 10 Days (in grams):\")\n",
        "print(nutrients)\n",
        "\n",
        "# Calculating total calories for each day\n",
        "total_calories_per_day = np.sum(nutrients * densities, axis=1)\n",
        "\n",
        "# Displaying total calories consumed each day\n",
        "print(\"\\nTotal Calories Consumed Each Day:\")\n",
        "print(total_calories_per_day)\n",
        "\n",
        "# Preparing data to save to file\n",
        "data_to_save = np.hstack((nutrients, total_calories_per_day.reshape(-1, 1)))\n",
        "\n",
        "# Specify the file path (saving in the current working directory)\n",
        "file_path = 'nutritional_data.csv'\n",
        "\n",
        "# Save to a CSV file\n",
        "np.savetxt(file_path, data_to_save, delimiter=',', header='Protein(g),Carbs(g),Fat(g),Total Calories', comments='')\n",
        "\n",
        "# Print the file path\n",
        "print(f\"\\nNutritional data saved to: {file_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC2kgHOCpSuU",
        "outputId": "d0807992-a589-46a4-b49a-077e6b66e0a0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nutritional Information (Protein, Carbs, Fat) over 10 Days (in grams):\n",
            "[[34 36 12]\n",
            " [26 42 41]\n",
            " [35 29 40]\n",
            " [32 47 23]\n",
            " [42 18 28]\n",
            " [18 16 49]\n",
            " [26 44 48]\n",
            " [19 29 16]\n",
            " [14 31 40]\n",
            " [45 16 32]]\n",
            "\n",
            "Total Calories Consumed Each Day:\n",
            "[388 641 616 523 492 577 712 336 540 532]\n",
            "\n",
            "Nutritional data saved to: nutritional_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Sophisticated Calorie Calculation\n",
        "# Dot product to calculate total calories\n",
        "import numpy as np\n",
        "\n",
        "# Assuming random data for demonstration\n",
        "nutrients = np.random.randint(10, 50, size=(10, 3))  # 10 days, 3 nutrients\n",
        "\n",
        "# Densities in calories per gram for Protein, Carbs, and Fat\n",
        "densities = np.array([4, 4, 9])  # 4 calories/gram for Protein and Carbs, 9 for Fat\n",
        "\n",
        "# Sophisticated Calorie Calculation for each day\n",
        "# Using np.dot for each row in nutrients array\n",
        "calories = np.dot(nutrients, densities)\n",
        "\n",
        "print(\"NumPy Calories per day:\")\n",
        "print(calories)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Wnf5DhspWpq",
        "outputId": "99262b65-cb91-41fb-84c8-fb5d298529d9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy Calories per day:\n",
            "[667 448 463 613 617 632 494 495 525 529]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nutrients is a 2D array where each row corresponds to a day and each column to a nutrient (protein, carbs, fat).\n",
        "The np.dot function is used to multiply the nutrients array with the densities array. Since nutrients is a 2D array and densities is a 1D array, np.dot will automatically handle this as a matrix-vector multiplication, resulting in a 1D array where each element is the total calorie count for each day.\n",
        "The printed calories array will display the total calories for each day."
      ],
      "metadata": {
        "id": "y3oekMmHxnNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Replicating Calculations in JAX\n",
        "\n",
        "# Converting the data to JAX arrays\n",
        "import jax.numpy as jnp\n",
        "import numpy as np  # Used only for random number generation\n",
        "\n",
        "# Setting a random seed for reproducibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# Assuming random data for demonstration\n",
        "# Note: JAX does not have its own randint, so we use NumPy for random data generation and then convert it to a JAX array\n",
        "nutrients = jnp.array(np.random.randint(10, 50, size=(10, 3)))  # 10 days, 3 nutrients\n",
        "\n",
        "# Densities in calories per gram for Protein, Carbs, and Fat\n",
        "densities = jnp.array([4, 4, 9])  # 4 calories/gram for Protein and Carbs, 9 for Fat\n",
        "\n",
        "# Sophisticated Calorie Calculation for each day\n",
        "# Using jnp.dot for each row in nutrients array\n",
        "calories = jnp.dot(nutrients, densities)\n",
        "\n",
        "print(\"JAX Calories per day:\")\n",
        "print(calories)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEE2DjWepcec",
        "outputId": "b572382b-782a-45b6-98fd-e9a4e2f2778f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JAX Calories per day:\n",
            "[209 533 605 506 564 634 611 335 359 392]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use numpy to generate the random data because JAX does not have a direct equivalent of numpy.random.randint. We then convert this data to a JAX array using jnp.array.\n",
        "For the densities and the dot product calculation, we use JAX's jax.numpy module, which functions similarly to NumPy but is compatible with JAX's accelerated computing capabilities."
      ],
      "metadata": {
        "id": "2w6oy_FYyXAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Advanced JAX Capabilities\n",
        "\n",
        "### Deep Dive into Just-in-Time Compilation (`jit`)\n",
        "\n",
        "import jax.numpy as jnp\n",
        "from jax import jit\n",
        "import numpy as np  # Used for random data generation\n",
        "\n",
        "# Setting a random seed for reproducibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# Generating random nutritional data (protein, carbs, fat) for 10 days\n",
        "nutrients = jnp.array(np.random.randint(10, 50, size=(10, 3)))\n",
        "\n",
        "# Densities in calories per gram for Protein, Carbs, and Fat\n",
        "densities = jnp.array([4, 4, 9])  # 4 calories/gram for Protein and Carbs, 9 for Fat\n",
        "\n",
        "# Function to calculate total calories\n",
        "def calculate_calories(nutrients, densities):\n",
        "    return jnp.dot(nutrients, densities)\n",
        "\n",
        "# JIT compilation to optimize the function\n",
        "jit_calculate_calories = jit(calculate_calories)\n",
        "\n",
        "# JIT-compiled function call\n",
        "calories = jit_calculate_calories(nutrients, densities)\n",
        "print(\"JIT Calories per day:\")\n",
        "print(calories)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3I1W6yMpi1T",
        "outputId": "5fcb03f7-e0e8-44b2-bfc1-84088563df70"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JIT Calories per day:\n",
            "[209 533 605 506 564 634 611 335 359 392]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Similar to JIT\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Setting a random seed for reproducibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# Generating random nutritional data (protein, carbs, fat) for 10 days\n",
        "nutrients = np.random.randint(10, 50, size=(10, 3))\n",
        "\n",
        "# Densities in calories per gram for Protein, Carbs, and Fat\n",
        "densities = np.array([4, 4, 9])  # 4 calories/gram for Protein and Carbs, 9 for Fat\n",
        "\n",
        "# Function to calculate total calories\n",
        "def calculate_calories(nutrients, densities):\n",
        "    return np.dot(nutrients, densities)\n",
        "\n",
        "# Function call\n",
        "calories = calculate_calories(nutrients, densities)\n",
        "print(\"NumPy Calories per day:\")\n",
        "print(calories)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq6kGO1czLQa",
        "outputId": "8f6b21c9-71e2-421e-f2e3-9f6eecb44af5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy Calories per day:\n",
            "[209 533 605 506 564 634 611 335 359 392]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's assume we have a function that not only calculates total calories but also includes a penalty term based on deviations from a target calorie count. This kind of function could be useful in nutritional planning or diet optimization, where we not only calculate calories but also want to minimize the deviation from a dietary goal."
      ],
      "metadata": {
        "id": "0tLB2E4DzinB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jax import grad\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "\n",
        "# Setting a random seed for reproducibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# Function to calculate calories with a penalty for deviation from a target\n",
        "def calculate_calories_with_penalty(nutrients, densities, target_calories):\n",
        "    total_calories = jnp.dot(nutrients, densities)\n",
        "    penalty = jnp.sum((total_calories - target_calories)**2)\n",
        "    return penalty\n",
        "\n",
        "# Example data: Nutrients for 10 days, converted to float for JAX compatibility\n",
        "nutrients = jnp.array(np.random.randint(10, 50, size=(10, 3)), dtype=jnp.float32)\n",
        "\n",
        "# Densities and target calories\n",
        "densities = jnp.array([4, 4, 9], dtype=jnp.float32)  # Protein, Carbs, Fat densities\n",
        "target_calories = 2000.0  # Example target calories, as float\n",
        "\n",
        "# Function to compute the gradient of calculate_calories_with_penalty\n",
        "grad_fn = grad(calculate_calories_with_penalty, argnums=0)  # Gradient w.r.t. nutrients\n",
        "\n",
        "# Compute the gradient\n",
        "gradient = grad_fn(nutrients, densities, target_calories)\n",
        "print(\"Gradient with respect to Nutrients:\")\n",
        "print(gradient)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhHY46PIppow",
        "outputId": "0eee32bb-2466-475d-89b1-86eef78c6c1a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient with respect to Nutrients:\n",
            "[[-14328. -14328. -32238.]\n",
            " [-11736. -11736. -26406.]\n",
            " [-11160. -11160. -25110.]\n",
            " [-11952. -11952. -26892.]\n",
            " [-11488. -11488. -25848.]\n",
            " [-10928. -10928. -24588.]\n",
            " [-11112. -11112. -25002.]\n",
            " [-13320. -13320. -29970.]\n",
            " [-13128. -13128. -29538.]\n",
            " [-12864. -12864. -28944.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Numpy we have to manually compute the gradient"
      ],
      "metadata": {
        "id": "OFUAKDXj0Ch8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Setting a random seed for reproducibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# Function to calculate calories with a penalty for deviation from a target\n",
        "def calculate_calories_with_penalty(nutrients, densities, target_calories):\n",
        "    total_calories = np.dot(nutrients, densities)\n",
        "    penalty = np.sum((total_calories - target_calories)**2)\n",
        "    return penalty\n",
        "\n",
        "# Function to manually compute the gradient of the penalty w.r.t. nutrients\n",
        "def grad_calories_with_penalty(nutrients, densities, target_calories):\n",
        "    total_calories = np.dot(nutrients, densities)\n",
        "    # Gradient calculation\n",
        "    grad_penalty = 2 * (total_calories - target_calories).reshape(-1, 1) * densities\n",
        "    return grad_penalty\n",
        "\n",
        "# Example data: Nutrients for 10 days\n",
        "nutrients = np.random.randint(10, 50, size=(10, 3))\n",
        "\n",
        "# Densities and target calories\n",
        "densities = np.array([4, 4, 9])  # Protein, Carbs, Fat densities\n",
        "target_calories = 2000  # Example target calories\n",
        "\n",
        "# Manually compute the gradient\n",
        "gradient = grad_calories_with_penalty(nutrients, densities, target_calories)\n",
        "print(\"Gradient with respect to Nutrients:\")\n",
        "print(gradient)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_MUwlCcz69X",
        "outputId": "c3205d46-8e8a-41c2-d973-0f4aa5557986"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient with respect to Nutrients:\n",
            "[[-14328 -14328 -32238]\n",
            " [-11736 -11736 -26406]\n",
            " [-11160 -11160 -25110]\n",
            " [-11952 -11952 -26892]\n",
            " [-11488 -11488 -25848]\n",
            " [-10928 -10928 -24588]\n",
            " [-11112 -11112 -25002]\n",
            " [-13320 -13320 -29970]\n",
            " [-13128 -13128 -29538]\n",
            " [-12864 -12864 -28944]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The concept of vectorization, particularly as implemented by JAX's vmap (vectorized map), is a powerful tool for parallel processing of batch data. It allows you to apply a function to each element of a batch simultaneously, rather than iterating through the batch in a loop. This is especially beneficial for performance when working with large datasets or simulations. Let's dive into this concept using an example in the context of caloric counting."
      ],
      "metadata": {
        "id": "g730vJvE0nNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example: Caloric Counting with Vectorization in JAX\n",
        "Suppose you have a function calculate_calories, which calculates the total calories based on the given nutrients and densities. Normally, this function would work on a single set of nutrients and densities. With vmap, you can easily extend this function to work on batches of data.\n",
        "\n",
        "First, let's define the calculate_calories function"
      ],
      "metadata": {
        "id": "B-c21oqY0rod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "\n",
        "def calculate_calories(nutrients, densities):\n",
        "    # Calculates total calories based on nutrients and densities\n",
        "    return jnp.dot(nutrients, densities)\n"
      ],
      "metadata": {
        "id": "5UpwCdDj0wfK"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's use vmap to vectorize this function for batch processing:"
      ],
      "metadata": {
        "id": "d1rN29T501Df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jax import vmap\n",
        "\n",
        "# Batched data: multiple sets of nutrients and densities\n",
        "batched_nutrients = jnp.array([[10, 20, 30], [1, 2, 3]])  # Two sets of nutrient data\n",
        "batched_densities = jnp.array([[4, 4, 9], [4, 4, 9]])     # Corresponding densities for each set\n",
        "\n",
        "# Vectorize the calorie calculation function\n",
        "vectorized_calories = vmap(calculate_calories)\n",
        "\n",
        "# Apply the vectorized function to the batched data\n",
        "all_calories = vectorized_calories(batched_nutrients, batched_densities)\n",
        "print(\"All Calories:\", all_calories)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr6n77mH0zJ0",
        "outputId": "9d771fdc-b4f9-480b-844e-d352ce21bd10"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Calories: [390  39]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Automatic differentiation is crucial in optimization and machine learning. JAX's `grad` makes obtaining gradients straightforward and efficient.\n",
        "\n",
        "### Comprehensive Look at Vectorization (`vmap`)\n",
        "\n",
        "from jax import vmap\n",
        "\n",
        "# Batch data for parallel computation\n",
        "batched_nutrients = jnp.array([[10, 20, 30], [1, 2, 3]])\n",
        "batched_densities = jnp.array([[4, 4, 9], [4, 4, 9]])\n",
        "\n",
        "# Vectorize the calorie calculation\n",
        "vectorized_calories = vmap(calculate_calories)\n",
        "all_calories = vectorized_calories(batched_nutrients, batched_densities)\n",
        "\n",
        "print(\"All Calories:\", all_calories)\n",
        "\n",
        "\n",
        "##`vmap` vectorizes functions, enabling parallel processing of batches, significantly improving performance for large datasets or simulations.\n"
      ],
      "metadata": {
        "id": "q8MolPEXpwa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code:\n",
        "\n",
        "batched_nutrients and batched_densities are arrays containing two sets of nutrient data and their corresponding densities.\n",
        "vmap(calculate_calories) creates a new function, vectorized_calories, which applies calculate_calories to each element (set of nutrients and densities) in the batch.\n",
        "all_calories is the result of applying vectorized_calories to the batched data, producing a batch of calorie counts.\n",
        "Advantages of Using vmap:\n",
        "Performance Improvement: vmap allows for parallel processing of the data, which can significantly speed up computations, especially with large batches of data.\n",
        "\n",
        "Code Simplicity: It simplifies the code by removing the need for explicit loops over batches. This makes the code more concise and easier to read.\n",
        "\n",
        "Flexibility: vmap can be used with many functions, allowing for easy vectorization of existing code."
      ],
      "metadata": {
        "id": "D9Bm3Qa_1CTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building and training a simple model using TensorFlow for NumPy data and then comparing it with a JAX-based approach for the same task.\n"
      ],
      "metadata": {
        "id": "HMhmBkox1wR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import jax.numpy as jnp\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load and preprocess meal data\n",
        "# Update the file path to the correct one\n",
        "df = pd.read_csv(\"/content/nutritional_data.csv\")\n",
        "X = df[['Protein(g)', 'Carbs(g)', 'Fat(g)']]  # Feature extraction\n",
        "y = df['Total Calories']  # Target variable (calories)\n",
        "\n",
        "# Splitting the dataset for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "# Convert to NumPy arrays for TensorFlow model\n",
        "X_train_np, y_train_np = np.array(X_train), np.array(y_train)\n",
        "\n",
        "# Convert to JAX arrays for JAX model\n",
        "X_train_jax, y_train_jax = jnp.array(X_train), jnp.array(y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "Dsx_vgIB1xb9"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import time\n",
        "\n",
        "# Building a neural network model using TensorFlow\n",
        "model_np = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(3,)),\n",
        "    Dense(1)\n",
        "])\n",
        "model_np.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Training the model with NumPy data\n",
        "start_time = time.time()\n",
        "model_np.fit(X_train_np, y_train_np, epochs=50)\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Training time with NumPy data:\", end_time - start_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI8A4XTW1zhe",
        "outputId": "74f7b607-7719-4305-8adc-0353f802d202"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 358875.2188\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 358284.8125\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 357695.6562\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 357107.4688\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 356520.2188\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 355934.2188\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 355349.2812\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 354767.1562\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 354184.5938\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 353602.4375\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 353019.5000\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 352437.7188\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 351857.0625\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 351277.5625\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 350699.2812\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 350122.1562\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 349546.2188\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 348971.5000\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 348397.0000\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 347822.1562\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 347248.4688\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 346678.0000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 346108.0000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 345538.9375\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 344972.6562\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 344409.1875\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 343846.8125\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 343285.4375\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 342725.0625\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 342165.5312\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 341605.8125\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 341046.3125\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 340488.3125\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 339932.1875\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 339376.6875\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 338820.7188\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 338264.4062\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 337703.1875\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 337141.8438\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 336580.4062\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 336019.4688\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 335457.7812\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 334896.6562\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 334338.9375\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 333785.9375\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 333232.8125\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 332680.3125\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 332126.1562\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 331564.0625\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 330997.9688\n",
            "Training time with NumPy data: 1.558666467666626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from flax import linen as nn\n",
        "from jax import random, grad, jit\n",
        "from flax.training import train_state\n",
        "import optax\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load and preprocess meal data\n",
        "df = pd.read_csv(\"/content/nutritional_data.csv\")\n",
        "X = df[['Protein(g)', 'Carbs(g)', 'Fat(g)']].values  # Extract features\n",
        "y = df['Total Calories'].values  # Extract target variable\n",
        "\n",
        "# Convert to JAX arrays\n",
        "X_jax = jnp.array(X)\n",
        "y_jax = jnp.array(y)\n",
        "\n",
        "# Splitting the dataset for training and testing\n",
        "X_train_jax, X_test_jax, y_train_jax, y_test_jax = train_test_split(X_jax, y_jax)\n",
        "\n",
        "# Define a simple neural network model using Flax\n",
        "class SimpleNN(nn.Module):\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        x = nn.Dense(32)(x)\n",
        "        x = nn.relu(x)\n",
        "        x = nn.Dense(1)(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "rng = jax.random.PRNGKey(0)\n",
        "input_shape = (1, 3)  # Shape for model initialization\n",
        "model = SimpleNN()\n",
        "params = model.init(rng, jnp.ones(input_shape))['params']\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optax.adam(learning_rate=0.001)\n",
        "state = train_state.TrainState.create(\n",
        "    apply_fn=model.apply, params=params, tx=optimizer)\n",
        "\n",
        "# Define the loss function\n",
        "def loss_fn(params, inputs, targets):\n",
        "    predictions = model.apply({'params': params}, inputs)\n",
        "    return jnp.mean((predictions - targets) ** 2)\n",
        "\n",
        "# Training step\n",
        "@jit\n",
        "def train_step(state, inputs, targets):\n",
        "    grads = grad(loss_fn)(state.params, inputs, targets)\n",
        "    return state.apply_gradients(grads=grads)\n",
        "\n",
        "# Training loop with timing\n",
        "start_time = time.time()\n",
        "for epoch in range(50):\n",
        "    state = train_step(state, X_train_jax, y_train_jax)\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"JAX model trained.\")\n",
        "print(\"Training time:\", end_time - start_time, \"seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH3haZGR2L9J",
        "outputId": "43958036-fc31-41c5-d477-ea493db64792"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JAX model trained.\n",
            "Training time: 1.3899955749511719 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why the Difference Might Not Be Pronounced in This Case:\n",
        "Small Dataset and Simple Model: The training task might be too small to highlight JAX's advantages in handling large-scale data and complex computations.\n",
        "\n",
        "Overhead of Initial Compilation in JAX: The first run in JAX includes JIT compilation time, which might offset some performance gains in short, one-off training runs.\n",
        "\n",
        "Optimization Differences: Different levels of optimization in TensorFlow and JAX (like default settings in optimizers, initialization, etc.) can lead to variations in training speed.\n",
        "\n",
        "Hardware Utilization: If the task isn’t large enough to fully utilize GPU/TPU capabilities, the difference in performance might not be as significant.\n",
        "\n",
        "Conclusion:\n",
        "While JAX showed a slight improvement in your specific test, its true strengths lie in scenarios that involve larger-scale data, complex mathematical computations, the need for automatic differentiation and advanced parallelization/vectorization capabilities. In simpler tasks or smaller datasets, these advantages might not be as pronounced, and the choice between JAX and NumPy/TensorFlow might be more influenced by factors like familiarity, existing codebases, or specific library features.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B4w5wDwg3Wgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next walkthrough: Employ Numpy and JAX in more complex use case related to caloric counting"
      ],
      "metadata": {
        "id": "RRBODLq13hSb"
      }
    }
  ]
}